{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Property Graph from Arrows App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property Graph Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Property Graph Design](../images/arrows_design.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Creating in Cypher:\n",
    "\n",
    "```\n",
    "CREATE (:Person {readUser: \"\", gender: \"\", age: \"\", ageGroup: \"\"})-[:INVOLVED_IN]->(n0:Crash {crashID: \"\", crashType: \"\", numberFatalities: \"\", busInvolvement: \"\", heavyRigidTruckInvolvement: \"\", articulatedTruckInvolvement: \"\", speedLimit: \"\"})-[:OCCURED_AT]->(:Location {state: \"\", nationalRemoteAreas: \"\", `sa4Name`: \"\", lgaName: \"\", nationalRoadType: \"\"}),\n",
    "(n0)-[:HAPPENED_AT]->(:DateTime {month: \"\", year: \"\", dayOfWeek: \"\", time: \"\", timeOfDay: \"\", weekdayOrWeekend: \"\", christmasPeriod: \"\", easterPeriod: \"\"})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL Process to Create CSVs for Neo4j Import\n",
    "We'll need to prepare 4 CSV files:\n",
    "\n",
    "1. `crash_nodes.csv` - All crash-related properties\n",
    "2. `person_nodes.csv` - All person-related properties  \n",
    "3. `location_nodes.csv` - All location-related properties\n",
    "4. `dateTime_nodes.csv` - All time-related properties\n",
    "\n",
    "And 3 relationship CSV files:\n",
    "\n",
    "1. `person_crash_rel.csv` - Connecting persons to crashes\n",
    "2. `crash_location_rel.csv` - Connecting crashes to locations  \n",
    "3. `crash_timeframe_rel.csv` - Connecting crashes to timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define input and output paths\n",
    "input_file = '../data/original/Project2_Dataset_Corrected.csv'  # Change this to your input CSV file name\n",
    "output_dir = '../data/filtered'  # Directory to store output CSV files\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from ../data/original/Project2_Dataset_Corrected.csv...\n",
      "Found 10490 records\n"
     ]
    }
   ],
   "source": [
    "# Read the original CSV file\n",
    "print(f\"Reading data from {input_file}...\")\n",
    "df = pd.read_csv(input_file)\n",
    "print(f\"Found {len(df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique IDs for nodes\n",
    "df['personId'] = df['ID'].astype(str)  # Using the original ID as personId\n",
    "df['locationId'] = df['Crash ID'].astype(str) + '_' + df['State'] + '_' + df['National Remoteness Areas'] + '_' + df['SA4 Name 2021'] + '_' + df['National LGA Name 2024'] + '_' + df['National Road Type']\n",
    "df['dateTimeId'] = df['Crash ID'].astype(str) + '_' + df['Month'].astype(str) + '_' + df['Year'].astype(str) + '_' + df['Time']\n",
    "\n",
    "# Prepare dataframes for each node type\n",
    "# Person nodes\n",
    "person_df = df[['personId', 'Road User', 'Gender', 'Age', 'Age Group', 'Crash ID']].copy()\n",
    "person_df.columns = ['personId', 'roadUser', 'gender', 'age', 'ageGroup', 'crashId']\n",
    "\n",
    "# Crash nodes\n",
    "crash_df = df[['Crash ID', 'Crash Type', 'Number Fatalities', 'Bus Involvement', \n",
    "               'Heavy Rigid Truck Involvement', 'Articulated Truck Involvement', \n",
    "               'Speed Limit']].copy()\n",
    "crash_df.columns = ['crashId', 'crashType', 'numberFatalities', 'busInvolvement', \n",
    "                    'heavyRigidTruckInvolvement', 'articulatedTruckInvolvement', 'speedLimit']\n",
    "\n",
    "# Remove duplicates to ensure unique crash nodes\n",
    "crash_df = crash_df.drop_duplicates(subset=['crashId'])\n",
    "\n",
    "# Location nodes\n",
    "location_df = df[['locationId', 'State', 'National Remoteness Areas', 'SA4 Name 2021', \n",
    "                  'National LGA Name 2024', 'National Road Type', 'Crash ID']].copy()\n",
    "location_df.columns = ['locationId', 'state', 'nationalRemoteAreas', 'sa4Name', \n",
    "                       'lgaName', 'nationalRoadType', 'crashId']\n",
    "\n",
    "# Remove duplicates to ensure unique location nodes\n",
    "location_df = location_df.drop_duplicates(subset=['locationId'])\n",
    "\n",
    "# DateTime nodes\n",
    "dateTime_df = df[['dateTimeId', 'Month', 'Year', 'Dayweek', 'Time', 'Time of day', \n",
    "                  'Day of week', 'Christmas Period', 'Easter Period', 'Crash ID']].copy()\n",
    "dateTime_df.columns = ['dateTimeId', 'month', 'year', 'dayOfWeek', 'time', 'timeOfDay', \n",
    "                      'weekdayOrWeekend', 'christmasPeriod', 'easterPeriod', 'crashId']\n",
    "\n",
    "# Remove duplicates to ensure unique datetime nodes\n",
    "dateTime_df = dateTime_df.drop_duplicates(subset=['dateTimeId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare relationship dataframes\n",
    "# For INVOLVED_IN relationship - Person to Crash\n",
    "person_crash_rel = person_df[['personId', 'crashId']].copy()\n",
    "\n",
    "# For OCCURED_AT relationship - Crash to Location\n",
    "crash_location_rel = location_df[['crashId', 'locationId']].copy()\n",
    "\n",
    "# For HAPPENED_AT relationship - Crash to DateTime\n",
    "crash_dateTime_rel = dateTime_df[['crashId', 'dateTimeId']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export node CSVs\n",
    "person_df.to_csv(f\"{output_dir}/person_nodes.csv\", index=False)\n",
    "crash_df.to_csv(f\"{output_dir}/crash_nodes.csv\", index=False)\n",
    "location_df.to_csv(f\"{output_dir}/location_nodes.csv\", index=False)\n",
    "dateTime_df.to_csv(f\"{output_dir}/dateTime_nodes.csv\", index=False)\n",
    "\n",
    "# Export relationship CSVs\n",
    "person_crash_rel.to_csv(f\"{output_dir}/person_crash_rel.csv\", index=False)\n",
    "crash_location_rel.to_csv(f\"{output_dir}/crash_location_rel.csv\", index=False)\n",
    "crash_dateTime_rel.to_csv(f\"{output_dir}/crash_dateTime_rel.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cypher commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_commands = f\"\"\"\n",
    "// Create constraints for unique IDs\n",
    "CREATE CONSTRAINT crash_id IF NOT EXISTS FOR (c:Crash) REQUIRE c.crashId IS UNIQUE;\n",
    "CREATE CONSTRAINT person_id IF NOT EXISTS FOR (p:Person) REQUIRE p.personId IS UNIQUE;\n",
    "CREATE CONSTRAINT location_id IF NOT EXISTS FOR (l:Location) REQUIRE l.locationId IS UNIQUE;\n",
    "CREATE CONSTRAINT dateTime_id IF NOT EXISTS FOR (d:DateTime) REQUIRE d.dateTimeId IS UNIQUE;\n",
    "\n",
    "// Import Crash nodes\n",
    "LOAD CSV WITH HEADERS FROM 'file:///crash_nodes.csv' AS row\n",
    "CREATE (c:Crash {{\n",
    "  crashId: row.crashId,\n",
    "  crashType: row.crashType,\n",
    "  numberFatalities: toInteger(row.numberFatalities),\n",
    "  busInvolvement: row.busInvolvement,\n",
    "  heavyRigidTruckInvolvement: row.heavyRigidTruckInvolvement,\n",
    "  articulatedTruckInvolvement: row.articulatedTruckInvolvement,\n",
    "  speedLimit: toInteger(row.speedLimit)\n",
    "}});\n",
    "\n",
    "// Import Person nodes\n",
    "LOAD CSV WITH HEADERS FROM 'file:///person_nodes.csv' AS row\n",
    "CREATE (p:Person {{\n",
    "  personId: row.personId,\n",
    "  roadUser: row.roadUser,\n",
    "  gender: row.gender,\n",
    "  age: toInteger(row.age),\n",
    "  ageGroup: row.ageGroup\n",
    "}});\n",
    "\n",
    "// Import Location nodes\n",
    "LOAD CSV WITH HEADERS FROM 'file:///location_nodes.csv' AS row\n",
    "CREATE (l:Location {{\n",
    "  locationId: row.locationId,\n",
    "  state: row.state,\n",
    "  nationalRemoteAreas: row.nationalRemoteAreas,\n",
    "  sa4Name: row.sa4Name,\n",
    "  lgaName: row.lgaName,\n",
    "  nationalRoadType: row.nationalRoadType\n",
    "}});\n",
    "\n",
    "// Import DateTime nodes\n",
    "LOAD CSV WITH HEADERS FROM 'file:///dateTime_nodes.csv' AS row\n",
    "CREATE (d:DateTime {{\n",
    "  dateTimeId: row.dateTimeId,\n",
    "  month: toInteger(row.month),\n",
    "  year: toInteger(row.year),\n",
    "  dayOfWeek: row.dayOfWeek,\n",
    "  time: row.time,\n",
    "  timeOfDay: row.timeOfDay,\n",
    "  weekdayOrWeekend: row.weekdayOrWeekend,\n",
    "  christmasPeriod: row.christmasPeriod,\n",
    "  easterPeriod: row.easterPeriod\n",
    "}});\n",
    "\n",
    "// Create Person-Crash relationships (INVOLVED_IN)\n",
    "LOAD CSV WITH HEADERS FROM 'file:///person_crash_rel.csv' AS row\n",
    "MATCH (p:Person {{personId: row.personId}})\n",
    "MATCH (c:Crash {{crashId: row.crashId}})\n",
    "CREATE (p)-[:INVOLVED_IN]->(c);\n",
    "\n",
    "// Create Crash-Location relationships (OCCURED_AT)\n",
    "LOAD CSV WITH HEADERS FROM 'file:///crash_location_rel.csv' AS row\n",
    "MATCH (c:Crash {{crashId: row.crashId}})\n",
    "MATCH (l:Location {{locationId: row.locationId}})\n",
    "CREATE (c)-[:OCCURED_AT]->(l);\n",
    "\n",
    "// Create Crash-DateTime relationships (HAPPENED_AT)\n",
    "LOAD CSV WITH HEADERS FROM 'file:///crash_dateTime_rel.csv' AS row\n",
    "MATCH (c:Crash {{crashId: row.crashId}})\n",
    "MATCH (d:DateTime {{dateTimeId: row.dateTimeId}})\n",
    "CREATE (c)-[:HAPPENED_AT]->(d);\n",
    "\n",
    "// Create indexes for better performance\n",
    "CREATE INDEX crash_speed_idx IF NOT EXISTS FOR (c:Crash) ON (c.speedLimit);\n",
    "CREATE INDEX crash_articulated_idx IF NOT EXISTS FOR (c:Crash) ON (c.articulatedTruckInvolvement);\n",
    "CREATE INDEX crash_fatalities_idx IF NOT EXISTS FOR (c:Crash) ON (c.numberFatalities);\n",
    "CREATE INDEX location_state_idx IF NOT EXISTS FOR (l:Location) ON (l.state);\n",
    "CREATE INDEX dateTime_year_idx IF NOT EXISTS FOR (d:DateTime) ON (d.year);\n",
    "CREATE INDEX person_age_group_idx IF NOT EXISTS FOR (p:Person) ON (p.ageGroup);\n",
    "CREATE INDEX person_road_user_idx IF NOT EXISTS FOR (p:Person) ON (p.roadUser);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j import commands saved to ../data/filtered/neo4j_import_commands.txt\n",
      "ETL process complete!\n"
     ]
    }
   ],
   "source": [
    "# Save Cypher commands to a file\n",
    "with open(f\"{output_dir}/neo4j_import_commands.txt\", \"w\") as f:\n",
    "    f.write(cypher_commands)\n",
    "\n",
    "print(f\"Neo4j import commands saved to {output_dir}/neo4j_import_commands.txt\")\n",
    "print(\"ETL process complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
